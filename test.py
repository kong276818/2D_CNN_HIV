import os
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import time
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import torchvision
from torchvision.io import read_image, ImageReadMode

# ===============================
# âœ… 1. ì„¤ì • í´ë˜ìŠ¤
# ===============================
class Config:
    """í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ê²½ë¡œ ì„¤ì •ì„ ìœ„í•œ í´ë˜ìŠ¤"""
    DATA_DIR = "dummy_dataset"  # ë°ì´í„°ë¥¼ ì½ì–´ì˜¬ í´ë” ì´ë¦„
    BATCH_SIZE = 4
    EPOCHS = 20
    LEARNING_RATE = 1e-4
    SAVE_PATH = "best_model_image_from_folders.pth"
    TRAIN_SPLIT = 0.7
    VALIDATION_SPLIT = 0.15
    TEST_SPLIT = 0.15
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ===============================
# âœ… 2. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ (ì´ë¯¸ì§€ í´ë” ê¸°ë°˜)
# ===============================
class ImageFolderDataset(Dataset):
    """ì§€ì •ëœ í´ë” êµ¬ì¡°ì—ì„œ ì´ë¯¸ì§€(.png, .jpg ë“±) ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, data_dir):
        self.image_files = []
        self.labels = []
        
        if not os.path.isdir(data_dir):
            raise FileNotFoundError(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ '{data_dir}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        self.class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])
        if not self.class_names:
            raise ValueError(f"'{data_dir}' ì•ˆì— í´ë˜ìŠ¤ í´ë”(ì˜ˆ: class_0)ê°€ ì—†ìŠµë‹ˆë‹¤.")

        print(f"ğŸ” í´ë˜ìŠ¤ ë°œê²¬: {self.class_names}")
        
        image_extensions = {'.png', '.jpg', '.jpeg', '.bmp', '.gif'}

        for label_idx, class_name in enumerate(self.class_names):
            class_path = os.path.join(data_dir, class_name)
            # í•˜ìœ„ í´ë”ê¹Œì§€ ëª¨ë‘ íƒìƒ‰
            for root, _, filenames in os.walk(class_path):
                for filename in filenames:
                    if os.path.splitext(filename)[1].lower() in image_extensions:
                        self.image_files.append(os.path.join(root, filename))
                        self.labels.append(label_idx)

        if not self.image_files:
            raise ValueError(f"'{data_dir}'ì˜ í•˜ìœ„ í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ëª¨ë“  ì´ë¯¸ì§€ì˜ H, W í¬ê¸°ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ê¸°ì¤€ìœ¼ë¡œ ë¡œë“œ
        print("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ í¬ê¸°ë¥¼ ë§ì¶”ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
        images_as_tensors = [self._load_and_process_image(path) for path in tqdm(self.image_files, desc="Loading images")]
        
        min_h = min(img.shape[1] for img in images_as_tensors)
        min_w = min(img.shape[2] for img in images_as_tensors)
        
        # ë°ì´í„°ë¥¼ ìµœì¢… Tensorë¡œ ë³€í™˜
        processed_images = [img[:, :min_h, :min_w] for img in images_as_tensors]
        self.images = torch.stack(processed_images)
        self.labels = torch.tensor(self.labels, dtype=torch.long)

        print(f"âœ… ì´ë¯¸ì§€ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: Images {self.images.shape}, Labels {self.labels.shape}")

    def _load_and_process_image(self, path):
        # ì´ë¯¸ì§€ë¥¼ RGBë¡œ ì½ê³  0-1 ì‚¬ì´ì˜ float ê°’ìœ¼ë¡œ ë³€í™˜
        img = read_image(path, mode=ImageReadMode.RGB)
        return img.float() / 255.0

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        return self.images[idx], self.labels[idx]

# ===============================
# âœ… 3. ëª¨ë¸ ì •ì˜ (ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°)
# ===============================
class ImageClassifier(nn.Module):
    """ì¼ë°˜ ì´ë¯¸ì§€ íŠ¹ì§•ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” CNN ëª¨ë¸"""
    def __init__(self, num_classes=2):
        super().__init__()
        # 3ì±„ë„(RGB) ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
        self.feature_extractor = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.BatchNorm2d(16), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),
            nn.AdaptiveAvgPool2d(1)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.5),
            nn.Linear(32, num_classes)
        )

    def forward(self, img):
        features = self.feature_extractor(img)
        output = self.classifier(features)
        return output

# ===============================
# âœ… 4. í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ===============================
def train_one_epoch(model, dataloader, criterion, optimizer, device):
    model.train()
    total_loss, all_preds, all_labels = 0, [], []
    for images, labels in tqdm(dataloader, desc="Training"):
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
        _, preds = torch.max(outputs, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
    
    if not dataloader: return 0.0, 0.0
    return total_loss / len(dataloader), accuracy_score(all_labels, all_preds)

def validate_one_epoch(model, dataloader, criterion, device):
    model.eval()
    total_loss, all_preds, all_labels = 0, [], []
    with torch.no_grad():
        for images, labels in tqdm(dataloader, desc="Validation"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    if not dataloader: return 0.0, 0.0
    return total_loss / len(dataloader), accuracy_score(all_labels, all_preds)

def evaluate_model(model, dataloader, device, class_names):
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for images, labels in tqdm(dataloader, desc="Testing"):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    if not all_labels:
        print("âš ï¸ ê²½ê³ : í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ì–´ ì„±ëŠ¥ ì¸¡ì •ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    print("\n--- ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ---")
    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))

    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title('Confusion Matrix')
    plt.show()

# ===============================
# âœ… 5. ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===============================
def main():
    cfg = Config()
    print(f"ğŸš€ Using device: {cfg.DEVICE}")

    full_dataset = ImageFolderDataset(cfg.DATA_DIR)
    dataset_size = len(full_dataset)

    test_size = int(cfg.TEST_SPLIT * dataset_size)
    val_size = int(cfg.VALIDATION_SPLIT * dataset_size)
    train_size = dataset_size - val_size - test_size

    if val_size <= 0 or test_size <= 0 or train_size <= 0:
        raise ValueError(f"ë°ì´í„°ì…‹ í¬ê¸°({dataset_size}ê°œ)ê°€ ë„ˆë¬´ ì‘ì•„ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” ë§ì€ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    train_dataset, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])
    
    train_loader = DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False)
    
    print(f"Split: {len(train_dataset)} train, {len(val_dataset)} validation, {len(test_dataset)} test samples.")

    model = ImageClassifier(num_classes=len(full_dataset.class_names)).to(cfg.DEVICE)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE)

    best_val_acc = 0.0
    start_time = time.time()
    for epoch in range(cfg.EPOCHS):
        print(f"\n--- Epoch {epoch+1}/{cfg.EPOCHS} ---")
        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, cfg.DEVICE)
        val_loss, val_acc = validate_one_epoch(model, val_loader, criterion, cfg.DEVICE)
        print(f"Epoch {epoch+1:02d} | Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save(model.state_dict(), cfg.SAVE_PATH)
            print(f"ğŸ‰ New best model saved with accuracy: {best_val_acc:.4f} to {cfg.SAVE_PATH}")

    total_time = time.time() - start_time
    print(f"\nâœ¨ Training complete in {total_time:.2f}s. Best validation accuracy: {best_val_acc:.4f}")

    if os.path.exists(cfg.SAVE_PATH):
        print(f"\nğŸ”¬ ìµœì  ëª¨ë¸({cfg.SAVE_PATH})ì„ ë¶ˆëŸ¬ì™€ ìµœì¢… ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤...")
        best_model = ImageClassifier(num_classes=len(full_dataset.class_names)).to(cfg.DEVICE)
        best_model.load_state_dict(torch.load(cfg.SAVE_PATH))
        evaluate_model(best_model, test_loader, cfg.DEVICE, full_dataset.class_names)
    else:
        print("\nâš ï¸ ì €ì¥ëœ ìµœì  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")


def prepare_dummy_data(data_dir="dummy_dataset"):
    """ì‹¤í–‰ì— í•„ìš”í•œ ë”ë¯¸ í´ë”ì™€ ì´ë¯¸ì§€(.png) ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    if os.path.exists(data_dir):
        return
    
    print(f"â„¹ï¸ '{data_dir}' í´ë”ì™€ ë”ë¯¸ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    os.makedirs(data_dir, exist_ok=True)
    
    for i in range(2): # class_0, class_1
        class_path = os.path.join(data_dir, f"class_{i}")
        os.makedirs(class_path, exist_ok=True)
        for j in range(20): # 20ê°œ ìƒ˜í”Œ
            # 3ì±„ë„(RGB)ì˜ 64x64 í¬ê¸° ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
            dummy_image = torch.randint(0, 256, (3, 64, 64), dtype=torch.uint8)
            torchvision.utils.save_image(dummy_image.float()/255.0, os.path.join(class_path, f"sample_{j}.png"))

if __name__ == "__main__":
    # prepare_dummy_data() # ë¡œì»¬ì—ì„œ í…ŒìŠ¤íŠ¸ ì‹œ ì£¼ì„ í•´ì œí•˜ì—¬ ë”ë¯¸ ë°ì´í„° ìƒì„±
    try:
        main()
    except (ValueError, FileNotFoundError) as e:
        print(f"\n--- ğŸš¨ ì˜¤ë¥˜ ë°œìƒ! ---")
        print(e)
        print("\n--- ğŸ’¡ í•´ê²° ë°©ë²• ---")
        print(f"1. '{Config.DATA_DIR}' í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print(f"2. '{Config.DATA_DIR}' í´ë” ì•ˆì— 'class_0', 'class_1'ê³¼ ê°™ì€ í•˜ìœ„ í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        print("3. ê° í´ë˜ìŠ¤ í´ë” ë˜ëŠ” ê·¸ í•˜ìœ„ í´ë”ì— .png, .jpg ë“±ì˜ ì´ë¯¸ì§€ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")